researchers have been applying geographic information systems (gis) to examine the roles of visibility
 and movement in archaeological landscapes around the world. however, few studies have investigated the role sound potentially played in structuring experience in ancient cities. to begin to fill this gap, this paper builds on our initial investigations to develop new geospatial and virtual reality (vr) methods to examine ancient acoustics. for the ancient maya, sight and sound worked in concert to create synesthetic experiences that influenced daily life and shaped society. to explore this interaction, we apply a combination of gis modeling: viewshed analysis, soundshed analysis, and an urban digital elevation model (urban dem) generated from airborne lidar and 3d modeling data. this approach provides an opportunity to perform computational analysis on a simulated ancient landscape rather than the contemporary landscape. we then take these gis-derived computational data into a vr environment to combine sound and vision to illustrate the complementary roles of visual and auditory experience at ancient copan.
